{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b420306",
   "metadata": {},
   "source": [
    "# Using online job postings to improve data science resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809d9ab",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "I want to find out what are the skills of data scientist not represented in my resume draft.  \n",
    "In order to improve the **CV** and start applying for the jobs.\n",
    "There is folder with all the job listings in HTML format.  \n",
    "Goal is to extract common data science skills and compare these skiils to the resume.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*rsJsA9wsN2Y5-o7HsItJ2A.jpeg\"\n",
    "     width=\"500\"\n",
    "     height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b175e",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "To achieve the goal we will do the following:\n",
    "\n",
    "1. Parse out all the text from the HTML files.\n",
    "2. Learn how job skills are commonly described in online postings.\n",
    "3. Filter irrelevant postings.\n",
    "4. Cluster the job skills within the relevant postings and visualize.\n",
    "5. Compare the clustered skills and our resume content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c976647",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ff2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc23b8",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4f4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458 HTML files have been loaded\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "html_contents = []\n",
    "\n",
    "with zipfile.ZipFile(\"job_postings.zip\", \"r\") as z:\n",
    "    for name in sorted(z.namelist()):\n",
    "        if name.endswith(\".html\"):\n",
    "            with z.open(name) as f:\n",
    "                html_contents.append(f.read().decode(\"utf-8\"))\n",
    "\n",
    "print(f\"{len(html_contents)} HTML files have been loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb859e9",
   "metadata": {},
   "source": [
    "Let's parse and store the parsed results in **soup_objects** list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a9aeb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1458</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1364</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Data Scientist - New York, NY</td>\n",
       "      <td>Data Scientist - Beavercreek, OH\\nData Scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Title  \\\n",
       "count                            1458   \n",
       "unique                           1364   \n",
       "top     Data Scientist - New York, NY   \n",
       "freq                               13   \n",
       "\n",
       "                                                     Body  \n",
       "count                                                1458  \n",
       "unique                                               1458  \n",
       "top     Data Scientist - Beavercreek, OH\\nData Scienti...  \n",
       "freq                                                    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup_objects = []\n",
    "for html in html_contents:\n",
    "    soup = bs(html)\n",
    "    assert soup.title is not None\n",
    "    assert soup.body is not None \n",
    "    soup_objects.append(soup)\n",
    "html_dict = {'Title':[], 'Body':[]}\n",
    "for soup in soup_objects:\n",
    "    title = soup.find('title').text\n",
    "    body = soup.find('body').text\n",
    "    html_dict['Title'].append(title)\n",
    "    html_dict['Body'].append(body)\n",
    "\n",
    "df_jobs = pd.DataFrame(html_dict)\n",
    "summary = df_jobs.describe()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771db412",
   "metadata": {},
   "source": [
    "There are 1364 unique titles out of 1458, the remaining 94 titles are duplicates.  \n",
    "\n",
    "The most common title repeated 13 times.  \n",
    "\n",
    "All 1458 bodies are unique, so none of the job postings occur more than once, even if some postings share common title.  \n",
    "  \n",
    "Now let's explore HTML content in more detail, the aim is to determine how jobs skills are described in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cef2c186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head><title>Patient Care Assistant / PCA - Med/Surg (Fayette, AL) - Fayette, AL</title></head>\n",
       "<body><h2>Patient Care Assistant / PCA - Med/Surg (Fayette, AL) - Fayette, AL</h2>\n",
       "<h1 class=\"jobSectionHeader\"><b>Performance Planning</b></h1>\n",
       "<p>Provides personal care and support services under the supervision of a registered nurse that assists the patient in the achievement of physical and emotional comfort.</p>\n",
       "<h1 class=\"jobSectionHeader\"><b>\n",
       "Key Responsibilities/Essential Functions</b></h1>\n",
       "<ul><li>Provides all personal care services in accordance with the plan of treatment assigned by the registered nurse</li><li>Accurately documents care provided</li><li>Applies safety principles and proper body mechanics to the performance of specific techniques of personal and supportive care, such as ambulation of patients, transferring patients, assisting with normal range of motions and positioning</li><li>Participates in economical utilization of supplies and ensures that equipment and nursing units are maintained in a clean, safe manner</li><li>Routinely follows and adheres to all policies and procedures</li><li>Assists in performance improvement (PI) activities by serving on PI teams as warranted, assisting with PI measures and supporting and implementing changes necessary for improvement</li></ul><ul><li>Maintains performance, patient and employee satisfaction and financial standards as outlined in the performance evaluation</li><li>Performs compliance requirements as outlined in the Employee Handbook</li><li>Must adhere to the DCH Behavioral Standards including creating positive relationships with patients/families, coworkers, colleagues and with self</li><li>Requires use of electronic mail, time and attendance software, learning management software and intranet</li><li>Must adhere to all DCH Health System policies and procedures</li><li>All other duties as assigned</li></ul><h1 class=\"jobSectionHeader\"><b>Minimum Knowledge, Skills, Experience Required</b></h1>\n",
       "<p>High School diploma or equivalent required. Basic Life Support training within 150 days of employment. Ability to meet behavioral expectations and work well with a team. Basic computer skills necessary to document patient care data into the clinical documentation system (vital signs, intake and output, etc.) Must be able to read, write, speak and comprehend English.\n",
       "</p><h1 class=\"jobSectionHeader\"><b>Working Conditions</b></h1>\n",
       "<p>Exposed to all patient care elements; subject to stress and fatigue. Prolonged periods of standing and/or walking; frequent kneeling and stooping. Ability to lift 50 pounds. Ability to transport, turn and position patients weighing up to 300 pounds. Vision and hearing normal or corrected to normal; manual dexterity to perform patient care tasks.</p></body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the skill desriptions\n",
    "assert len(set(html_contents)) == len(html_contents)\n",
    "display(HTML(html_contents[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e14f5",
   "metadata": {},
   "source": [
    "There are usually 2 subsections, 1 for Responsibilities and 1 for Qualifications.  \n",
    "  \n",
    "They are not that different, yet qualifications focus on tools and concepts, while responsibilities are covering actions to be performed on the job.  \n",
    "  \n",
    "Let's divide posting description into 2 parts:\n",
    "  \n",
    "  \n",
    "A. Initial job summary.  \n",
    "\n",
    "B. List of skills required to get a job "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6787bc",
   "metadata": {},
   "source": [
    "Do these types of skills desriptions also appear in other job postings.  \n",
    "Let' extract the bullets from each of parsed HTML files. \n",
    "Bullet point is taged in \"li\" and appears as dot in the html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729ddcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a list of bullet points from soup object by calling following function\n",
    "df_jobs['Bullets'] = [[bullet.text.strip() for bullet in soup.find_all('li') ]for soup in soup_objects]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafeaa5e",
   "metadata": {},
   "source": [
    "We created new col \"Bullets\" to store all the bullet points, however, it may also be possible that majority of the job postings simply don't contain any!   \n",
    "  \n",
    "Let's find out the percentages of postings that actually contain bulleted text.  \n",
    "  \n",
    "If it's too low it is worth changing the approach of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2fda2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.53% of the postings contain bullet points \n"
     ]
    }
   ],
   "source": [
    "bulleted_post_count = 0\n",
    "for bullet_list in df_jobs.Bullets:\n",
    "    if bullet_list:\n",
    "        bulleted_post_count += 1\n",
    "percent_bulleted = 100 * bulleted_post_count / df_jobs.shape[0]\n",
    "print(f\"{percent_bulleted:.2f}% of the postings contain bullet points \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32fb347",
   "metadata": {},
   "source": [
    "Okay, next step is to understand whether most of these bullets focus on skills.  \n",
    "For that matter let's print out top-ranked words in their text. \n",
    "For ranking we will use **Term Frequency Inverse Document Frequency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06191b79",
   "metadata": {},
   "source": [
    "### **How TFIDF Created**\n",
    "TF-IDF is the product of two distinct metrics designed to balance local importance and global rarity:\n",
    "\n",
    "1.  **Term Frequency (TF):** Measures how frequently a word appears in a specific document.\n",
    "    *   *Core Idea:* If a word appears often, it is likely important to that documentâ€™s topic.\n",
    "    *   *Formula:* $\\text{TF}(t, d) = \\frac{\\text{Count of term } t \\text{ in document } d}{\\text{Total number of words in document } d}$.\n",
    "2.  **Inverse Document Frequency (IDF):** Measures how rare a word is across the entire corpus.\n",
    "    *   *Core Idea:* Common words (like \"the\" or \"is\") appear in many documents and provide little unique information, so they are penalized with a lower weight.\n",
    "    *   *Formula:* $\\text{IDF}(t) = \\log\\left(\\frac{\\text{Total number of documents}}{\\text{Number of documents containing term } t}\\right)$.\n",
    "3.  **Final Score:** $\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0ffa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Words  Summed TFIDF\n",
      "experience    878.030398\n",
      "      data    842.978780\n",
      "    skills    440.780236\n",
      "      work    371.684232\n",
      "   ability    370.969638\n"
     ]
    }
   ],
   "source": [
    "def rank_words(text_list):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfdidf_matrix = vectorizer.fit_transform(text_list).toarray()\n",
    "    df = pd.DataFrame({'Words': vectorizer.get_feature_names_out(),\n",
    "                       \"Summed TFIDF\": tfdidf_matrix.sum(axis=0)})\n",
    "    sorted_df = df.sort_values('Summed TFIDF', ascending=False)\n",
    "    return sorted_df\n",
    "all_bullets = []\n",
    "for bullet_list in df_jobs.Bullets:\n",
    "    all_bullets.extend(bullet_list)\n",
    "sorted_df = rank_words(all_bullets)\n",
    "print(sorted_df[:5].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d269289",
   "metadata": {},
   "source": [
    "Terms such as **skills** and **ability** appear among the top five bulleted words.\n",
    "Most likely the bullets correspond to individual job skills.  \n",
    "How do these bulleted words compare to the remaining words in each job posting?  \n",
    "  \n",
    "  \n",
    "We iterate over the body of each posting and delete any bulleted lists using Beautiful Soup *decompose* method. \n",
    "Then we extract the remaining body text and store it in a non_bullets list. \n",
    "Finally, we apply rank_words function that lists and display the top five non-bullet words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc56f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Words  Summed TFIDF\n",
      "      data     99.111312\n",
      "      team     39.175041\n",
      "      work     38.928948\n",
      "experience     36.820836\n",
      "  business     36.140488\n"
     ]
    }
   ],
   "source": [
    "non_bullets = []\n",
    "for soup in soup_objects:\n",
    "    body = soup.body\n",
    "    for tag in body.find_all('li'):\n",
    "        tag.decompose()\n",
    "    non_bullets.append(body.text)\n",
    "sorted_df = rank_words(non_bullets)\n",
    "print(sorted_df[:5].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6d288",
   "metadata": {},
   "source": [
    "The words **skills** and **ability** are no longer present in the ranked output. \n",
    "They have been replaced by the words **business** and **team**. Thus, non-bulleted text appears to be less skill oriented.  \n",
    "  \n",
    "Words *data*, *experience* and *work* top ranked words that are shared between bullets and non-bulleted.  \n",
    "Strangely words **science** and **scientist** are missing.  \n",
    "\n",
    "Logic question arises, do some posts pertain to data-driven jobs aren't directly *data science* jobs? \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb362863",
   "metadata": {},
   "source": [
    "Let's iterate over all the titles across all jobs and checking if each title mentions a data science position.  \n",
    "Then, we will measure the percentages of jobs where data science and data scientist are missing from the titles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
