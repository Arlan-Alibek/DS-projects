{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b420306",
   "metadata": {},
   "source": [
    "# Using online job postings to improve data science resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809d9ab",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "I want to find what are the skills not represented in my resume draft.  \n",
    "There is folder with all the job listings in HTML format.  \n",
    "Goal is to extract common data science skills and compare these skiils to the resume.\n",
    "\n",
    "<img src=\"https://www.flexjobs.com/blog/wp-content/uploads/2019/11/04164452/functional-resume.png?w=1024\"\n",
    "     width=\"500\"\n",
    "     height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640b8f38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1b175e",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "To achieve the goal we will do the following:\n",
    "\n",
    "1. Parse out all the text from the HTML files.\n",
    "2. Learn how job skills are commonly described in online postings.\n",
    "3. Filter irrelevant postings.\n",
    "4. Cluster the job skills within the relevant postings and visualize.\n",
    "5. Compare the clustered skills and our resume content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c976647",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ff2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc23b8",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4f4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458 HTML files have been loaded\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "html_contents = []\n",
    "\n",
    "with zipfile.ZipFile(\"job_postings.zip\", \"r\") as z:\n",
    "    for name in sorted(z.namelist()):\n",
    "        if name.endswith(\".html\"):\n",
    "            with z.open(name) as f:\n",
    "                html_contents.append(f.read().decode(\"utf-8\"))\n",
    "\n",
    "print(f\"{len(html_contents)} HTML files have been loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb859e9",
   "metadata": {},
   "source": [
    "Let's parse and store the parsed results in **soup_objects** list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9aeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_objects = []\n",
    "for html in html_contents:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
