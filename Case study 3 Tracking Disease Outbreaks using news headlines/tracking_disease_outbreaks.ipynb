{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77598638",
   "metadata": {},
   "source": [
    "# Tracking disease outbreaks using new headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4da6c3",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "We monitor disease epidemics and critical component of the monitoring process is analyzing published news data.  \n",
    "\n",
    "Thus, we will process daily quota of news headlines and extract locations that are mentioned in the news.  \n",
    "Afterwards, we will cluster the headlines based on their geographic distribution.\n",
    "\n",
    "<img src=\"https://www.yourgenome.org/wp-content/uploads/2023/11/1600-shutterstock_2112088307-1440x760.jpg.webp\"\n",
    "     width=\"500\"\n",
    "     height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b5fe7",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "  \n",
    "The file headlines.txt contains the hundreds of headlines that should be analyzed.  \n",
    "Each headline appears on a separate line in the file.  \n",
    "  \n",
    "## Goal of the project. \n",
    "  \n",
    "We will extract locations from disease-related headlines to uncover the largest active epidemics.  \n",
    "Then cluster the locations based on geographic distance. \n",
    "Afterwards, we'll visualize clusters on a map.  \n",
    "Finally, the output is representative locations from the largest clusters for conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1be60b",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df0adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import re\n",
    "from geonamescache import GeonamesCache # database for geographical data\n",
    "gc = GeonamesCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff51d9",
   "metadata": {},
   "source": [
    "### Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30831ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650 headlines have been loaded\n"
     ]
    }
   ],
   "source": [
    "headlines_file = open('headlines.txt','r')\n",
    "headlines = [line.strip() for line in headlines_file.readlines()]\n",
    "num_headlines = len(headlines)\n",
    "print(f\"{num_headlines} headlines have been loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d50ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create function that would transform each location name into compiled regular expression.\n",
    "\n",
    "def name_to_regex(name):\n",
    "    decoded_name = unidecode(name)\n",
    "    if name != decoded_name:\n",
    "        regex = fr'\\b({name}|{decoded_name})\\b'\n",
    "    else:\n",
    "        regex = fr'\\b{name}\\b'\n",
    "    return re.compile(regex,flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a6d5b",
   "metadata": {},
   "source": [
    "Using name_to_regex we can create a mapping between regular expressions and the original names in GeoNamesCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba06277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
